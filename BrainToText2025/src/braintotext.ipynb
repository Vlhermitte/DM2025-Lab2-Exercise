{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 106809,
     "databundleVersionId": 13056355,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:30.378691Z",
     "start_time": "2025-11-29T07:50:30.354126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:30.401130Z",
     "start_time": "2025-11-29T07:50:30.382963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"  # Enable CPU fallback for MPS\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Disable high watermark for MPS\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:30.419983Z",
     "start_time": "2025-11-29T07:50:30.404308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from config import Configurator\n",
    "from data import NeuralDataset, collate_transducer, load_h5py_file, ids_to_text\n",
    "\n",
    "Config = Configurator(phoneme=False)\n",
    "Config.Train = False\n",
    "path = Config.DATA_PATH\n",
    "device = Config.DEVICE"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:31.074109Z",
     "start_time": "2025-11-29T07:50:30.424476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataframes(path):\n",
    "    folders = os.listdir(path)\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    val_files = []\n",
    "    for i, files in enumerate(folders):\n",
    "        if files.startswith(\".\"):\n",
    "            continue\n",
    "        files = os.listdir(os.path.join(path, files))\n",
    "        for file in files:\n",
    "            if file.endswith(\"train.hdf5\"):\n",
    "                train_files.append(os.path.join(path, folders[i], file))\n",
    "            elif file.endswith(\"val.hdf5\"):\n",
    "                val_files.append(os.path.join(path, folders[i], file))\n",
    "            elif file.endswith(\"test.hdf5\"):\n",
    "                test_files.append(os.path.join(path, folders[i], file))\n",
    "\n",
    "    train_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for file in tqdm(train_files, desc=\"Loading train files\"):\n",
    "        data = load_h5py_file(file)\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        train_df = pd.concat([train_df, temp_df], ignore_index=True)\n",
    "        if Config.DEBUG:\n",
    "            i += 1\n",
    "            if i >= 1:  # load only 4 files in debug mode\n",
    "                break\n",
    "\n",
    "    val_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for file in tqdm(val_files, desc=\"Loading val files\"):\n",
    "        data = load_h5py_file(file)\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        val_df = pd.concat([val_df, temp_df], ignore_index=True)\n",
    "        if Config.DEBUG:\n",
    "            i += 1\n",
    "            if i >= 1:  # load only 2 files in debug mode\n",
    "                break\n",
    "\n",
    "    return train_df, val_df, test_files\n",
    "\n",
    "train_df, val_df, test_files = get_dataframes(path)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train files:   0%|          | 0/45 [00:00<?, ?it/s]\n",
      "Loading val files:   0%|          | 0/41 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:31.955607Z",
     "start_time": "2025-11-29T07:50:31.077882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ------------------------ Dataset and Dataloader ------------------------\n",
    "train_dataset = NeuralDataset(train_df, augment=True, smoothing=True)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_transducer(b, pad_id=Config.PAD_ID, batch_first=Config.BATCH_FIRST)\n",
    ")\n",
    "\n",
    "val_dataset = NeuralDataset(val_df, augment=True, smoothing=True)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_transducer(b, pad_id=Config.PAD_ID, batch_first=Config.BATCH_FIRST)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.066566Z",
     "start_time": "2025-11-29T07:50:32.050389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models import ConformerEncoderDecoder\n",
    "from training import Trainer, EarlyStopping"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.222408Z",
     "start_time": "2025-11-29T07:50:32.069405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Define your Simpler Model\n",
    "model = ConformerEncoderDecoder(\n",
    "    vocab_size=Config.VOCAB_SIZE,\n",
    ").to(device)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.241040Z",
     "start_time": "2025-11-29T07:50:32.225966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "lr = 3e-3\n",
    "model_checkpoint_path = \"./best_model.pth\""
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.274988Z",
     "start_time": "2025-11-29T07:50:32.244211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=Configurator.PAD_ID)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=lr,\n",
    "    weight_decay=1e-2\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=lr,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=num_epochs,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    epochs=num_epochs,\n",
    "    early_stop=EarlyStopping(patience=10, min_delta=1e-3, path=model_checkpoint_path),\n",
    "    batch_first=Config.BATCH_FIRST,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.294311Z",
     "start_time": "2025-11-29T07:50:32.278116Z"
    }
   },
   "cell_type": "code",
   "source": "# trainer.run()",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:32.314021Z",
     "start_time": "2025-11-29T07:50:32.297657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_single_prediction(model, dataset, index=0):\n",
    "    device = Config.DEVICE\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Get one sample\n",
    "    x, y_ids = dataset[index] # x is (T, 512), y_ids is (L,)\n",
    "\n",
    "    # 2. Prepare inputs\n",
    "    x = x.unsqueeze(0).to(device) # Add batch dim: (1, T, 512)\n",
    "    x_len = torch.tensor([x.size(1)], dtype=torch.long).to(device)\n",
    "\n",
    "    # 3. Predict\n",
    "    print(f\"Input Shape: {x.shape}\")\n",
    "    print(\"Generating text...\")\n",
    "\n",
    "    # Returns tensor of IDs including SOS and EOS\n",
    "    predicted_ids = model.predict(\n",
    "        x,\n",
    "        x_len,\n",
    "        max_len=200,\n",
    "        sos_id=Config.SOS_ID,\n",
    "        eos_id=Config.EOS_ID\n",
    "    )\n",
    "\n",
    "    # 4. Decode to String\n",
    "    # Remove batch dim and convert to list\n",
    "    pred_id_list = predicted_ids[0].cpu().tolist()\n",
    "\n",
    "    # Convert IDs to Text (using your new helper in data.py)\n",
    "    predicted_text = ids_to_text(pred_id_list)\n",
    "    ground_truth = ids_to_text(y_ids.tolist())\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Ground Truth: {ground_truth}\")\n",
    "    print(f\"Prediction:   {predicted_text}\")\n",
    "    print(\"-\" * 30)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:33.967931Z",
     "start_time": "2025-11-29T07:50:32.318665Z"
    }
   },
   "cell_type": "code",
   "source": "run_single_prediction(model, val_dataset, index=0)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([1, 978, 512])\n",
      "Generating text...\n",
      "------------------------------\n",
      "Ground Truth: Qeb\u001Dcolpqv\u001D^fo\u001Dm^ppba\u001Dqeolrde\u001Dqeb\u001D`l^q+\n",
      "Prediction:   *i*F+*F&ti*F=7*\tx*\tx*\tx*\tx*\tx*\tx*\tx*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\tx*i*\tx*\tx*i*\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T07:50:34.072972Z",
     "start_time": "2025-11-29T07:50:34.071468Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
